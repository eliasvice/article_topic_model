{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic Modeling Amarigna\n",
    "\n",
    "_ Simple topic classifying LSTM model to test if it is possible to identify topics in Amharic text _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import keras, numpy as np\n",
    "from keras.layers import Embedding, Dense, LSTM, GRU\n",
    "from keras.models import Sequential\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_A small sample dataset to train and test the model_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-30e2c7a91d88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata_loc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./data/big_sample.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m';'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'article_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'url_fragment'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'first_published'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'topic'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# data.columns = ['article_id', 'url_fragment', 'first_published', 'body', 'topic']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/envs/deep/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/envs/deep/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/envs/deep/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1067\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'skipfooter not supported for iteration'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1069\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'as_recarray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/envs/deep/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1837\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1838\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1839\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1840\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1841\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n"
     ]
    }
   ],
   "source": [
    "data_loc = \"./data/big_sample.csv\"\n",
    "data = pd.read_csv(data_loc, sep=';', names=['article_id', 'url_fragment', 'first_published', 'body', 'topic'])\n",
    "# data.columns = ['article_id', 'url_fragment', 'first_published', 'body', 'topic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5910888242026c28fac35d30     my very short pregnancy was extremely traumat...\n",
       "5910888242026c28fac35d30     my very short pregnancy was extremely traumat...\n",
       "5910888242026c28fac35d30     my very short pregnancy was extremely traumat...\n",
       "5910888242026c28fac35d30     my very short pregnancy was extremely traumat...\n",
       "592304c2fb5b53475047e666                                                 easy\n",
       "592304c2fb5b53475047e666                                               dinner\n",
       "5925cf4ab377dd5e042bec48                                              classic\n",
       "5925cf4ab377dd5e042bec48                                                chili\n",
       "5952d2e5068490541f4ad204                                                snack\n",
       "590a0fb9f68fc128e293301f                                              noodles\n",
       "590a0fb9f68fc128e293301f                                                 easy\n",
       "590a0fb9f68fc128e293301f                                               dinner\n",
       "5a14729a3858494222ebb024     they brought my daughter a stuffed animal whi...\n",
       "5a14729a3858494222ebb024     they brought my daughter a stuffed animal whi...\n",
       "5a14729a3858494222ebb024     they brought my daughter a stuffed animal whi...\n",
       "5a14729a3858494222ebb024     they brought my daughter a stuffed animal whi...\n",
       "59bc3a598f1d6523034b3f08     it's the stuff of stoner dreams and a perfect...\n",
       "59f74c292fbf3e08a193898f     repeat until you have a stack of 2 sheets. Tr...\n",
       "59f74c292fbf3e08a193898f     repeat until you have a stack of 2 sheets. Tr...\n",
       "59f74c292fbf3e08a193898f     repeat until you have a stack of 2 sheets. Tr...\n",
       "5a271157cfe6f06878d486f2                                              vermont\n",
       "5a271157cfe6f06878d486f2                                              america\n",
       "5a1f1dc474149c4a1c51c8d4                                          portraiture\n",
       "5a393cf9e03d0e0e7e9c0db8                                              seafood\n",
       "5a393cf9e03d0e0e7e9c0db8                                                 easy\n",
       "5a393cf9e03d0e0e7e9c0db8                                           vegetables\n",
       "5a393cf9e03d0e0e7e9c0db8                                             tomatoes\n",
       "5a3a949ae03d0e0e7e9c1a3e                                                   uk\n",
       "5a3a949ae03d0e0e7e9c1a3e                                                  age\n",
       "5a3a949ae03d0e0e7e9c1a3e                                                death\n",
       "                                                  ...                        \n",
       "5a7319a8ea61e05a285e484d                                            holocaust\n",
       "5a610395272fb0118c7b9e5d                                              alcohol\n",
       "5a539f224889b903525c692e                                           vegetarian\n",
       "5a53ad54195444648780def8                                                 fire\n",
       "5a53ad54195444648780def8                                                vgtrn\n",
       "5a53ad54195444648780def8                                          trump tower\n",
       "5a4cf9c2af51a603465d400c                                               dating\n",
       "5a4cf9c2af51a603465d400c                                                   uk\n",
       "5a6f6d6fc003d95c0f75633e                                               russia\n",
       "5a6f6d6fc003d95c0f75633e                                 russia investigation\n",
       "5a7319a8ea61e05a285e484d                                             politics\n",
       "5a732cd1f089885b328687ae                                           super bowl\n",
       "5a6f74f50ceee651804b693b                                                power\n",
       "5a610395272fb0118c7b9e5d                                                 body\n",
       "5a5e7a00b5113d0b1833df72                                               israel\n",
       "5a5e874bbc23990b05338d9f      Horizon’s world was as beautiful as it was e...\n",
       "5a610395272fb0118c7b9e5d                                                world\n",
       "5a4cf9c2af51a603465d400c                                        relationships\n",
       "5a4d32b3991db6032cfcb4b3                                               police\n",
       "5a4d44b5ef55e4647a696bd1                                              weather\n",
       "5a53ad54195444648780def8                                             accident\n",
       "5a53d1b0195444648780e0a3                                 non-commercial games\n",
       "5a53d1b0195444648780e0a3                                              itch.io\n",
       "5a53d1b0195444648780e0a3                                            free play\n",
       "5a73308e99bdc95b40af2111                                                 tech\n",
       "5a73308e99bdc95b40af2111                                               russia\n",
       "5a73442121457468fe892653                                                abuse\n",
       "5a610aabb6b1a01180e47f1d                                              therapy\n",
       "5a6f74f50ceee651804b693b                                           government\n",
       "5a6f7b13e56c635186a2f66f     a George W. Bush–lovin’ Republican who isn’t ...\n",
       "Name: body, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['article_id', 'url_fragment', 'first_published', 'body', 'topic'], dtype='object')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_words = 100000\n",
    "max_seq_len = 2000\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(np.floor(data.shape[0] * .8))\n",
    "\n",
    "train_x = data[\"body\"][0:train_size]\n",
    "train_y = data[\"topic\"][0:train_size]\n",
    "\n",
    "test_x = data[\"body\"][train_size:]\n",
    "test_y = data[\"topic\"][train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((800,), (800,), (200,), (200,))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape, train_y.shape, test_x.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[\"body\"]\n",
    "y = data[\"topic\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "183"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics = list(y.unique())\n",
    "y_encoded = [topics.index(topic) for topic in y] \n",
    "\n",
    "n_classes = len(topics)\n",
    "n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5910888242026c28fac35d30                                        mental health\n",
       "5910888242026c28fac35d30                                                 body\n",
       "5910888242026c28fac35d30                                                 mind\n",
       "5910888242026c28fac35d30                                           psychology\n",
       "592304c2fb5b53475047e666                                                  NaN\n",
       "592304c2fb5b53475047e666                                                  NaN\n",
       "5925cf4ab377dd5e042bec48                                                  NaN\n",
       "5925cf4ab377dd5e042bec48                                                  NaN\n",
       "5952d2e5068490541f4ad204                                                  NaN\n",
       "590a0fb9f68fc128e293301f                                                  NaN\n",
       "590a0fb9f68fc128e293301f                                                  NaN\n",
       "590a0fb9f68fc128e293301f                                                  NaN\n",
       "5a14729a3858494222ebb024     it seemed like they were in some kind of fina...\n",
       "5a14729a3858494222ebb024     it seemed like they were in some kind of fina...\n",
       "5a14729a3858494222ebb024     it seemed like they were in some kind of fina...\n",
       "5a14729a3858494222ebb024     it seemed like they were in some kind of fina...\n",
       "59bc3a598f1d6523034b3f08                                              hot dog\n",
       "59f74c292fbf3e08a193898f                                                 easy\n",
       "59f74c292fbf3e08a193898f                                                lunch\n",
       "59f74c292fbf3e08a193898f                                               dinner\n",
       "5a271157cfe6f06878d486f2                                                  NaN\n",
       "5a271157cfe6f06878d486f2                                                  NaN\n",
       "5a1f1dc474149c4a1c51c8d4                                                  NaN\n",
       "5a393cf9e03d0e0e7e9c0db8                                                  NaN\n",
       "5a393cf9e03d0e0e7e9c0db8                                                  NaN\n",
       "5a393cf9e03d0e0e7e9c0db8                                                  NaN\n",
       "5a393cf9e03d0e0e7e9c0db8                                                  NaN\n",
       "5a3a949ae03d0e0e7e9c1a3e                                                  NaN\n",
       "5a3a949ae03d0e0e7e9c1a3e                                                  NaN\n",
       "5a3a949ae03d0e0e7e9c1a3e                                                  NaN\n",
       "                                                  ...                        \n",
       "5a4e4d7413866d648050b27d                                                  NaN\n",
       "5a4e4d7413866d648050b27d                                                  NaN\n",
       "5a4e4d7413866d648050b27d                                                  NaN\n",
       "5914928b2a91401a4ef70c4d                                                  NaN\n",
       "5914928b2a91401a4ef70c4d                                                  NaN\n",
       "5914928b2a91401a4ef70c4d                                                  NaN\n",
       "5a3957ffc11170024c975c6c                                                  NaN\n",
       "5a4e60944889b903525c52cb                                                  NaN\n",
       "5a4e7ed44889b903525c5405     the cream slides on your skin as a thin film,...\n",
       "5a4e861734a88864620788a1     in one story, he stripped down to Versace bri...\n",
       "5a271157cfe6f06878d486f2                                                  NaN\n",
       "5a466dcc3ad54a2f3164b64c                                                  NaN\n",
       "5a466dcc3ad54a2f3164b64c                                                  NaN\n",
       "5a4ec530991db6032cfcbf77                                                  NaN\n",
       "5a4eee5c4399b46468a130e2                                                  NaN\n",
       "5a4eee5c4399b46468a130e2                                                  NaN\n",
       "5a4fc492b878556488e80197                                                 mind\n",
       "5a4fc492b878556488e80197                                          masculinity\n",
       "5a466dcc3ad54a2f3164b64c                                                  NaN\n",
       "5a466dcc3ad54a2f3164b64c                                                  NaN\n",
       "5a48124451b1fe284654531c                                                  NaN\n",
       "5a4fc492b878556488e80197                                              therapy\n",
       "5a4fc492b878556488e80197                                        relationships\n",
       "5a4fc492b878556488e80197                                        mental health\n",
       "5a4fc492b878556488e80197                                           psychology\n",
       "5a4fda6b6ae38d646e30535d                                                  NaN\n",
       "5a4ff50978e6000358f86124                                                  NaN\n",
       "5a5004426ae38d646e305455     in recent years, a line from the film—“ain’t ...\n",
       "5a5004426ae38d646e305455     in recent years, a line from the film—“ain’t ...\n",
       "5a3957ffc11170024c975c6c                                                  NaN\n",
       "Name: topic, Length: 100, dtype: object"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.topic[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing the data for the model\n",
    "* Tokenizing the text - Identifying unique words, creating a dictionary and counting their frequency in the list of documents (texts) in the training data.\n",
    "* One-hot encoding the labels (topics)\n",
    "* Splitting the data into train and test(validation) sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=nb_words)\n",
    "tokenizer.fit_on_texts(X)\n",
    "sequences = Tokenizer.texts_to_sequences(tokenizer, X)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "ydata = keras.utils.to_categorical(y_encoded)\n",
    "input_data = pad_sequences(sequences, maxlen=max_seq_len)\n",
    "\n",
    "Xtrain, Xvalid, ytrain, yvalid = train_test_split(input_data, ydata, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Model definition and training_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 2000, 64)          653888    \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 80)                46400     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 183)               14823     \n",
      "=================================================================\n",
      "Total params: 715,111\n",
      "Trainable params: 715,111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embedding_vector_length = 64\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index)+1, embedding_vector_length, input_length=max_seq_len, embeddings_initializer='glorot_normal', \n",
    "                    embeddings_regularizer=keras.regularizers.l2(0.01)))\n",
    "model.add(LSTM(80))\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eliashussen/.pyenv/versions/3.6.3/envs/deep/lib/python3.6/site-packages/keras/models.py:981: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/10\n",
      "800/800 [==============================] - 87s 109ms/step - loss: 2.3164 - acc: 0.6637 - val_loss: 2.3248 - val_acc: 0.6850\n",
      "Epoch 2/10\n",
      "800/800 [==============================] - 89s 111ms/step - loss: 2.2065 - acc: 0.6637 - val_loss: 2.2234 - val_acc: 0.6850\n",
      "Epoch 3/10\n",
      "800/800 [==============================] - 88s 110ms/step - loss: 1.9524 - acc: 0.6637 - val_loss: 1.9456 - val_acc: 0.6850\n",
      "Epoch 4/10\n",
      "800/800 [==============================] - 88s 109ms/step - loss: 1.8601 - acc: 0.6637 - val_loss: 1.8619 - val_acc: 0.6850\n",
      "Epoch 5/10\n",
      "800/800 [==============================] - 88s 109ms/step - loss: 1.7442 - acc: 0.6637 - val_loss: 1.8474 - val_acc: 0.6850\n",
      "Epoch 6/10\n",
      "800/800 [==============================] - 87s 109ms/step - loss: 1.7071 - acc: 0.6637 - val_loss: 1.8214 - val_acc: 0.6850\n",
      "Epoch 7/10\n",
      "800/800 [==============================] - 88s 110ms/step - loss: 1.6849 - acc: 0.6663 - val_loss: 1.8462 - val_acc: 0.6900\n",
      "Epoch 8/10\n",
      "800/800 [==============================] - 89s 111ms/step - loss: 1.6635 - acc: 0.6713 - val_loss: 1.8384 - val_acc: 0.6900\n",
      "Epoch 9/10\n",
      "800/800 [==============================] - 87s 109ms/step - loss: 1.6446 - acc: 0.6713 - val_loss: 1.8610 - val_acc: 0.6900\n",
      "Epoch 10/10\n",
      "800/800 [==============================] - 89s 111ms/step - loss: 1.6297 - acc: 0.6713 - val_loss: 1.8878 - val_acc: 0.6900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1242c2e48>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xtrain, ytrain, validation_data=(Xvalid, yvalid), nb_epoch=10, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = model.predict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
